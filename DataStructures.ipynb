{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArezoShakeri/NLP-Project1/blob/main/DataStructures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxOkcvB9sqy6"
      },
      "source": [
        "<font color=\"#00d2d3\">Build Vocabulary - aka Preprocessing Words into Cleaned Tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVQ6RanQYPdp"
      },
      "source": [
        "#<font color='#4cd137'> Bag oF Words Architecture in creating a Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzCx_Vrwf46L"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ-FmV5cgAJE"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE-9F3jpgFZF"
      },
      "source": [
        "text = [\n",
        "  'A rose is a flower',\n",
        "  'A fern is not a flower',\n",
        "  'the dog ate the rose',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWtfOhYsjEBX"
      },
      "source": [
        "<font color='#4cd137'> Creating a pandas series object from the list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUBN1gj7gFfv",
        "outputId": "e8dfe24b-c34b-4b2d-ff4d-96f4d378e556"
      },
      "source": [
        "corpus_vocab = pd.Series(text)\n",
        "corpus_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        A rose is a flower\n",
              "1    A fern is not a flower\n",
              "2      the dog ate the rose\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQC-5EYpjtj_"
      },
      "source": [
        "[Keras Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)<br> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHzcf-YSgJpt"
      },
      "source": [
        "model = Tokenizer()\n",
        "model.fit_on_texts(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRng1MUuoAr7"
      },
      "source": [
        "the Tokenizer provides 4 attributes :\n",
        "\n",
        "word_counts,\n",
        "word_docs,\n",
        "word_index,\n",
        "document_count\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwqqUi7Ygbiu",
        "outputId": "2058b4d8-cb86-4e20-edd8-12c7ed100802"
      },
      "source": [
        "print(f'Key : {list(model.word_index.keys())}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key : ['a', 'rose', 'is', 'flower', 'the', 'fern', 'not', 'dog', 'ate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sqD2CfZgJvO",
        "outputId": "3ce64c2c-2368-4b42-8134-b5a0e8c5a3a7"
      },
      "source": [
        "vec_rep = model.texts_to_matrix(text, mode='count')\n",
        "vec_rep #numpy array of shape (len(texts), num_words)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 2., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 2., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 2., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = [\n",
        "  'Elizabeth was very clever',\n",
        "  'she had a difficult childhood',\n",
        "  ' she was famous',\n",
        "  'the future cannot be foreseen',\n",
        "  'she never expected to be queen',\n",
        "  'the crown passed to daughter',\n",
        "  'she married',\n",
        "  'she was shy '\n",
        "]"
      ],
      "metadata": {
        "id": "vimIbJ19vcGF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_vocab = pd.Series(text2)\n",
        "corpus_vocab"
      ],
      "metadata": {
        "id": "c83vNJKIvg7k",
        "outputId": "13664363-8d6d-4db0-da70-13d6cbd29abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Elizabeth was very clever\n",
              "1     she had a difficult childhood\n",
              "2                    she was famous\n",
              "3     the future cannot be foreseen\n",
              "4    she never expected to be queen\n",
              "5      the crown passed to daughter\n",
              "6                       she married\n",
              "7                      she was shy \n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Tokenizer()\n",
        "model2.fit_on_texts(text2)"
      ],
      "metadata": {
        "id": "dCbRIRLuvls-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Key : {list(model2.word_index.keys())}')"
      ],
      "metadata": {
        "id": "PzgNwEkEvmiy",
        "outputId": "ffa1dbbd-6b07-4dcc-d0f5-8367528e371e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key : ['she', 'was', 'the', 'be', 'to', 'elizabeth', 'very', 'clever', 'had', 'a', 'difficult', 'childhood', 'famous', 'future', 'cannot', 'foreseen', 'never', 'expected', 'queen', 'crown', 'passed', 'daughter', 'married', 'shy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_rep = model2.texts_to_matrix(text2, mode='count')\n",
        "vec_rep"
      ],
      "metadata": {
        "id": "hJspqmEQvvvY",
        "outputId": "6637ce4e-3713-49f3-dee5-0ee20437aa15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}